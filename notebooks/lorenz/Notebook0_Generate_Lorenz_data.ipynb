{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5be26e-1541-4a24-b9c9-c4b2f67868f2",
   "metadata": {},
   "source": [
    "# Generate Lorenz data\n",
    "\n",
    "This notebook accompanies the following publication:\n",
    "Paul Platzer, Arthur Avenas, Bertrand Chapron, Lucas Drumetz, Alexis Mouche, Léo Vinour. Distance Learning for Analog Methods. 2024. [⟨hal-04841334⟩](https://hal.science/hal-04841334)\n",
    "\n",
    "It is used to generate two trajectories of the Lorenz system that will be used in numerical experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c3935a-b27b-44cc-bfbb-1a2b545f19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "sys.path.append('../../functions/.')\n",
    "from generate_lorenz import RK4, l63, integrate_l63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c5b7f3-6be9-4f2f-bb62-a3c36e724a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../data/lorenz/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c244e83-dfeb-4b51-8fbb-9a783ea9f0b4",
   "metadata": {},
   "source": [
    "# Generate catalog for sections 3.a and 3.c\n",
    "In these sections, the algorithm is tested on different variables, at different forecasting horizons, and to compare the MSE-based and CRPS-based optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6b956d-f17d-42f6-ace6-ef510751c719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e73a0c4086743beb264a653f53dfab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6400447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set parameters\n",
    "Ntrain = 10**5\n",
    "tau = 0.64 # time between two elements of the catalogue (2 \"days\")\n",
    "dt = 0.01 # integration time-step\n",
    "h_max = 4.48 # maximal forecast horizon to be tested (2 \"weeks\")\n",
    "Ntraj = Ntrain*int(tau/dt) + int(h_max/dt)\n",
    "\n",
    "# Integrate\n",
    "traj = integrate_l63( dt = dt , N = Ntraj )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855ab812-634e-4208-8fdc-d6233ee4d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "stds = np.std(traj, axis=0)\n",
    "traj_norm = traj/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d995ed2a-5b31-48dd-8a16-2123850a0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output (146.5 MB)\n",
    "np.savez(data_folder + 'catalog_small.npz', \n",
    "         traj_norm = traj_norm, stds = stds,\n",
    "        Ntrain = Ntrain, tau = tau, dt = dt, h_max = h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc9697b-5709-4969-8b31-df4775dd4826",
   "metadata": {},
   "source": [
    "# Generate catalogs for section 3.b\n",
    "In this section, the algorithm is tested for different catalog sizes. The integration here is longer ($\\sim$20 minutes per catalog, with 10 catalogs) and will generate larger files ($\\sim$1.4GB per catalog). Depending on your computational resources and requirements, this code could modified to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a79842-4676-4d07-a160-eeaa4ee3ad18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a237b62d8d4adeac8c849587abe006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74df01d76a1c4638a2125a40da234fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64000447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m train0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1.5\u001b[39m,\u001b[38;5;241m2.5\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.25\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.5\u001b[39m][j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.01\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Integrate\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m traj \u001b[38;5;241m=\u001b[39m \u001b[43mintegrate_l63\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNtraj\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m     18\u001b[0m stds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(traj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/pro/postdoc/learn_distance/Paper1_Metric_Learning_For_Analogue_Methods/codes_revision1/functions/generate_lorenz.py:40\u001b[0m, in \u001b[0;36mintegrate_l63\u001b[0;34m(X0, dt, N, spin_up)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Integrate\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 40\u001b[0m     traj[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mRK4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml63\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m traj\n",
      "File \u001b[0;32m~/Documents/pro/postdoc/learn_distance/Paper1_Metric_Learning_For_Analogue_Methods/codes_revision1/functions/generate_lorenz.py:15\u001b[0m, in \u001b[0;36mRK4\u001b[0;34m(yt, h, f)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRK4\u001b[39m(yt,h,f):\n\u001b[1;32m     14\u001b[0m     k1\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m*\u001b[39mf(yt)\n\u001b[0;32m---> 15\u001b[0m     k2\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m*\u001b[39m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43myt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     k3\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m*\u001b[39mf(yt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mk2)\n\u001b[1;32m     17\u001b[0m     k4\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m*\u001b[39mf(yt\u001b[38;5;241m+\u001b[39mk3)\n",
      "File \u001b[0;32m~/Documents/pro/postdoc/learn_distance/Paper1_Metric_Learning_For_Analogue_Methods/codes_revision1/functions/generate_lorenz.py:22\u001b[0m, in \u001b[0;36ml63\u001b[0;34m(Xt, sigma, rho, beta)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m yt\u001b[38;5;241m+\u001b[39mdy\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m## Equations of the Lorenz (1963) system\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ml63\u001b[39m(Xt, sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, rho \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m28\u001b[39m, beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     23\u001b[0m     xdot\u001b[38;5;241m=\u001b[39msigma\u001b[38;5;241m*\u001b[39m(Xt[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mXt[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     24\u001b[0m     ydot\u001b[38;5;241m=\u001b[39mXt[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m(rho\u001b[38;5;241m-\u001b[39mXt[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m-\u001b[39mXt[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "Ntrain = 10**6\n",
    "tau = 0.64 # time between two elements of the catalogue (2 \"days\")\n",
    "dt = 0.01 # integration time-step\n",
    "h_max = 4.48 # maximal forecast horizon to be tested (2 \"weeks\")\n",
    "Ntraj = Ntrain*int(tau/dt) + int(h_max/dt)\n",
    "\n",
    "# Loop on catalog\n",
    "for j in tqdm(range(10)):\n",
    "\n",
    "    # Initial condition (there will be a spin-up of 1000 time-steps to ensure the beginning of the catalog is inside the attractor)\n",
    "    train0 = np.array([1,1,1]) + [1,2,3,-1,-2,-3,1.5,2.5,-.25,-.5][j]*0.01*np.random.randn(3)\n",
    "    \n",
    "    # Integrate\n",
    "    traj = integrate_l63( X0 = train0, dt = dt , N = Ntraj )\n",
    "    \n",
    "    # Normalize\n",
    "    stds = np.std(traj, axis=0)\n",
    "    traj_norm = traj/stds\n",
    "    \n",
    "    # Store\n",
    "    np.savez(data_folder + 'catalog_large_'+str(j)+'.npz',\n",
    "             traj_norm = traj_norm, stds = stds, \n",
    "            Ntrain = Ntrain, tau = tau, dt = dt, h_max = h_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497dfd86-53ff-4193-9822-bac6561f34d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
